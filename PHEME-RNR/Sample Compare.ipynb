{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b150a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers.data.processors.utils import InputExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "034f28a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_comments</th>\n",
       "      <th>text_only</th>\n",
       "      <th>comments_only</th>\n",
       "      <th>label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Breaking: At least 10 dead, 5 injured after tO...</td>\n",
       "      <td>Breaking: At least 10 dead, 5 injured after tO...</td>\n",
       "      <td>The religion of peace strikes again.\\n[SEP]Hi ...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
       "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
       "      <td>MT France: 10 dead after shooting at HQ of sat...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ten killed in shooting at headquarters of Fren...</td>\n",
       "      <td>Ten killed in shooting at headquarters of Fren...</td>\n",
       "      <td>must be that peace loving religion again\\n[SEP...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BREAKING: 10 dead in shooting at headquarters ...</td>\n",
       "      <td>BREAKING: 10 dead in shooting at headquarters ...</td>\n",
       "      <td>WTF &amp;gt; BREAKING 10 dead in shooting at headq...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reuters: 10 people shot dead at headquarters o...</td>\n",
       "      <td>Reuters: 10 people shot dead at headquarters o...</td>\n",
       "      <td>watch yourself in Paris bud\\n[SEP]islamist ter...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text_comments  \\\n",
       "0  Breaking: At least 10 dead, 5 injured after tO...   \n",
       "1  France: 10 people dead after shooting at HQ of...   \n",
       "2  Ten killed in shooting at headquarters of Fren...   \n",
       "3  BREAKING: 10 dead in shooting at headquarters ...   \n",
       "4  Reuters: 10 people shot dead at headquarters o...   \n",
       "\n",
       "                                           text_only  \\\n",
       "0  Breaking: At least 10 dead, 5 injured after tO...   \n",
       "1  France: 10 people dead after shooting at HQ of...   \n",
       "2  Ten killed in shooting at headquarters of Fren...   \n",
       "3  BREAKING: 10 dead in shooting at headquarters ...   \n",
       "4  Reuters: 10 people shot dead at headquarters o...   \n",
       "\n",
       "                                       comments_only   label  count  \n",
       "0  The religion of peace strikes again.\\n[SEP]Hi ...  rumour      9  \n",
       "1  MT France: 10 dead after shooting at HQ of sat...  rumour      7  \n",
       "2  must be that peace loving religion again\\n[SEP...  rumour      5  \n",
       "3  WTF &gt; BREAKING 10 dead in shooting at headq...  rumour     13  \n",
       "4  watch yourself in Paris bud\\n[SEP]islamist ter...  rumour     16  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('./data/raw_data.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fdce415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_comments</th>\n",
       "      <th>text_only</th>\n",
       "      <th>comments_only</th>\n",
       "      <th>label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Breaking: At least 10 dead, 5 injured after tO...</td>\n",
       "      <td>Breaking: At least 10 dead, 5 injured after tO...</td>\n",
       "      <td>The religion of peace strikes again.\\n[SEP]Hi ...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
       "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
       "      <td>MT France: 10 dead after shooting at HQ of sat...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ten killed in shooting at headquarters of Fren...</td>\n",
       "      <td>Ten killed in shooting at headquarters of Fren...</td>\n",
       "      <td>must be that peace loving religion again\\n[SEP...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BREAKING: 10 dead in shooting at headquarters ...</td>\n",
       "      <td>BREAKING: 10 dead in shooting at headquarters ...</td>\n",
       "      <td>WTF &amp;gt; BREAKING 10 dead in shooting at headq...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reuters: 10 people shot dead at headquarters o...</td>\n",
       "      <td>Reuters: 10 people shot dead at headquarters o...</td>\n",
       "      <td>watch yourself in Paris bud\\n[SEP]islamist ter...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10 people have died in a shooting at the Paris...</td>\n",
       "      <td>10 people have died in a shooting at the Paris...</td>\n",
       "      <td>herregud RT@SkyNews: 10 people have died in a ...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>French radio says attackers on offices of Pari...</td>\n",
       "      <td>French radio says attackers on offices of Pari...</td>\n",
       "      <td>figures....when will France and the EU learn.\\...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BREAKING: 10 reportedly shot dead at Paris HQ ...</td>\n",
       "      <td>BREAKING: 10 reportedly shot dead at Paris HQ ...</td>\n",
       "      <td>How dreadful.\\n[SEP]Nowhere is safe anymore? \"...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BREAKING NEWS: Ten dead in shooting at headqua...</td>\n",
       "      <td>BREAKING NEWS: Ten dead in shooting at headqua...</td>\n",
       "      <td>â€œ@jenanmoussa: BREAKING NEWS: Ten dead in shoo...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Witness says multiple gunmen involved in shoot...</td>\n",
       "      <td>Witness says multiple gunmen involved in shoot...</td>\n",
       "      <td>En franÃ§ais et plus Ã  jour\\n[SEP]This issue m...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text_comments  \\\n",
       "0  Breaking: At least 10 dead, 5 injured after tO...   \n",
       "1  France: 10 people dead after shooting at HQ of...   \n",
       "2  Ten killed in shooting at headquarters of Fren...   \n",
       "3  BREAKING: 10 dead in shooting at headquarters ...   \n",
       "4  Reuters: 10 people shot dead at headquarters o...   \n",
       "5  10 people have died in a shooting at the Paris...   \n",
       "6  French radio says attackers on offices of Pari...   \n",
       "7  BREAKING: 10 reportedly shot dead at Paris HQ ...   \n",
       "8  BREAKING NEWS: Ten dead in shooting at headqua...   \n",
       "9  Witness says multiple gunmen involved in shoot...   \n",
       "\n",
       "                                           text_only  \\\n",
       "0  Breaking: At least 10 dead, 5 injured after tO...   \n",
       "1  France: 10 people dead after shooting at HQ of...   \n",
       "2  Ten killed in shooting at headquarters of Fren...   \n",
       "3  BREAKING: 10 dead in shooting at headquarters ...   \n",
       "4  Reuters: 10 people shot dead at headquarters o...   \n",
       "5  10 people have died in a shooting at the Paris...   \n",
       "6  French radio says attackers on offices of Pari...   \n",
       "7  BREAKING: 10 reportedly shot dead at Paris HQ ...   \n",
       "8  BREAKING NEWS: Ten dead in shooting at headqua...   \n",
       "9  Witness says multiple gunmen involved in shoot...   \n",
       "\n",
       "                                       comments_only   label  count  \n",
       "0  The religion of peace strikes again.\\n[SEP]Hi ...  rumour      9  \n",
       "1  MT France: 10 dead after shooting at HQ of sat...  rumour      7  \n",
       "2  must be that peace loving religion again\\n[SEP...  rumour      5  \n",
       "3  WTF &gt; BREAKING 10 dead in shooting at headq...  rumour     13  \n",
       "4  watch yourself in Paris bud\\n[SEP]islamist ter...  rumour     16  \n",
       "5  herregud RT@SkyNews: 10 people have died in a ...  rumour     22  \n",
       "6  figures....when will France and the EU learn.\\...  rumour     10  \n",
       "7  How dreadful.\\n[SEP]Nowhere is safe anymore? \"...  rumour      3  \n",
       "8  â€œ@jenanmoussa: BREAKING NEWS: Ten dead in shoo...  rumour     10  \n",
       "9   En franÃ§ais et plus Ã  jour\\n[SEP]This issue m...  rumour      2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rumour_data = raw_data[raw_data['label']=='rumour']\n",
    "rumour_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9baa68da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = rumour_data.sample(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a04233d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data1 = sample_data[['text_comments','label']]\n",
    "sample_data1 = sample_data1.rename(columns = {'text_comments':'text'})\n",
    "sample_data1['label'] = LabelEncoder().fit_transform(sample_data1['label'])\n",
    "\n",
    "sample_data2 = sample_data[['text_only','label']]\n",
    "sample_data2 = sample_data2.rename(columns = {'text_only':'text'})\n",
    "sample_data2['label'] = LabelEncoder().fit_transform(sample_data2['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ce1d149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4011</th>\n",
       "      <td>Updated: The shooting incident in Ottawa had t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>In 2009 #Ferguson PD beat a black man, then ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>So police narrative in #Ferguson is unarmed te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>I hope for everyones sake that this is fake bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4103</th>\n",
       "      <td>Sergeant-at-Arms Kevin Vickers hailed as hero ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>KKK already raising money for the police offic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>Ottawa shooting: Nathan Cirillo, reservist fro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>Update: Five hostages escape as a gunman conti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>#CharlieHebdo latest:\\n- 2 gunmen believed hol...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>BREAKING: A #Lufthansa #Germanwings Airbus jet...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>The selective release of information by #Fergu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4837</th>\n",
       "      <td>#BREAKING: Reports that some of the hostages h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>Anybody else thinks the #Ferguson police chief...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785</th>\n",
       "      <td>LIVE: coverage of ongoing hostage situation in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4055</th>\n",
       "      <td>Soldier shot dead in #Ottawa today is Cpl. Nat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4102</th>\n",
       "      <td>Gut-wrenching to hear the soldier guarding our...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4926</th>\n",
       "      <td>BREAKING NEWS: GUNMAN DEMANDING TO SPEAK TO AU...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4062</th>\n",
       "      <td>Corporal Nathan Cirillo, shot dead at #Ottawa ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5033</th>\n",
       "      <td>BREAKING : multiple gunshots fired into Lindt ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>French police confirm that the #CharlieHebdo a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "4011  Updated: The shooting incident in Ottawa had t...      0\n",
       "2195  In 2009 #Ferguson PD beat a black man, then ch...      0\n",
       "2181  So police narrative in #Ferguson is unarmed te...      0\n",
       "4983  I hope for everyones sake that this is fake bu...      0\n",
       "4103  Sergeant-at-Arms Kevin Vickers hailed as hero ...      0\n",
       "2130  KKK already raising money for the police offic...      0\n",
       "4081  Ottawa shooting: Nathan Cirillo, reservist fro...      0\n",
       "4960  Update: Five hostages escape as a gunman conti...      0\n",
       "279   #CharlieHebdo latest:\\n- 2 gunmen believed hol...      0\n",
       "3259  BREAKING: A #Lufthansa #Germanwings Airbus jet...      0\n",
       "2198  The selective release of information by #Fergu...      0\n",
       "4837  #BREAKING: Reports that some of the hostages h...      0\n",
       "2338  Anybody else thinks the #Ferguson police chief...      0\n",
       "4785  LIVE: coverage of ongoing hostage situation in...      0\n",
       "4055  Soldier shot dead in #Ottawa today is Cpl. Nat...      0\n",
       "4102  Gut-wrenching to hear the soldier guarding our...      0\n",
       "4926  BREAKING NEWS: GUNMAN DEMANDING TO SPEAK TO AU...      0\n",
       "4062  Corporal Nathan Cirillo, shot dead at #Ottawa ...      0\n",
       "5033  BREAKING : multiple gunshots fired into Lindt ...      0\n",
       "91    French police confirm that the #CharlieHebdo a...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "936e65bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4011</th>\n",
       "      <td>Updated: The shooting incident in Ottawa had t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>In 2009 #Ferguson PD beat a black man, then ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>So police narrative in #Ferguson is unarmed te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>I hope for everyones sake that this is fake bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4103</th>\n",
       "      <td>Sergeant-at-Arms Kevin Vickers hailed as hero ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>KKK already raising money for the police offic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>Ottawa shooting: Nathan Cirillo, reservist fro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>Update: Five hostages escape as a gunman conti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>#CharlieHebdo latest:\\n- 2 gunmen believed hol...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>BREAKING: A #Lufthansa #Germanwings Airbus jet...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>The selective release of information by #Fergu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4837</th>\n",
       "      <td>#BREAKING: Reports that some of the hostages h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>Anybody else thinks the #Ferguson police chief...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785</th>\n",
       "      <td>LIVE: coverage of ongoing hostage situation in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4055</th>\n",
       "      <td>Soldier shot dead in #Ottawa today is Cpl. Nat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4102</th>\n",
       "      <td>Gut-wrenching to hear the soldier guarding our...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4926</th>\n",
       "      <td>BREAKING NEWS: GUNMAN DEMANDING TO SPEAK TO AU...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4062</th>\n",
       "      <td>Corporal Nathan Cirillo, shot dead at #Ottawa ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5033</th>\n",
       "      <td>BREAKING : multiple gunshots fired into Lindt ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>French police confirm that the #CharlieHebdo a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "4011  Updated: The shooting incident in Ottawa had t...      0\n",
       "2195  In 2009 #Ferguson PD beat a black man, then ch...      0\n",
       "2181  So police narrative in #Ferguson is unarmed te...      0\n",
       "4983  I hope for everyones sake that this is fake bu...      0\n",
       "4103  Sergeant-at-Arms Kevin Vickers hailed as hero ...      0\n",
       "2130  KKK already raising money for the police offic...      0\n",
       "4081  Ottawa shooting: Nathan Cirillo, reservist fro...      0\n",
       "4960  Update: Five hostages escape as a gunman conti...      0\n",
       "279   #CharlieHebdo latest:\\n- 2 gunmen believed hol...      0\n",
       "3259  BREAKING: A #Lufthansa #Germanwings Airbus jet...      0\n",
       "2198  The selective release of information by #Fergu...      0\n",
       "4837  #BREAKING: Reports that some of the hostages h...      0\n",
       "2338  Anybody else thinks the #Ferguson police chief...      0\n",
       "4785  LIVE: coverage of ongoing hostage situation in...      0\n",
       "4055  Soldier shot dead in #Ottawa today is Cpl. Nat...      0\n",
       "4102  Gut-wrenching to hear the soldier guarding our...      0\n",
       "4926  BREAKING NEWS: GUNMAN DEMANDING TO SPEAK TO AU...      0\n",
       "4062  Corporal Nathan Cirillo, shot dead at #Ottawa ...      0\n",
       "5033  BREAKING : multiple gunshots fired into Lindt ...      0\n",
       "91    French police confirm that the #CharlieHebdo a...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52d2ecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_InputExamples = sample_data1.apply(lambda x: InputExample(guid=None, text_a = x['text'], text_b = None, label = x['label']), axis = 1)\n",
    "\n",
    "data2_InputExamples = sample_data2.apply(lambda x: InputExample(guid=None, text_a = x['text'], text_b = None, label = x['label']), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16dd0721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torchtext.data import BucketIterator\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from transformers import (\n",
    "    WEIGHTS_NAME,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    BertConfig,\n",
    "    BertModel,\n",
    "    BertPreTrainedModel,\n",
    "    BertTokenizer,\n",
    "    BertweetTokenizer,\n",
    "    AutoModel,\n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "from transformers import glue_convert_examples_to_features as convert_examples_to_features\n",
    "from transformers import glue_output_modes as output_modes\n",
    "from transformers import glue_processors as processors\n",
    "from transformers.data.processors.utils import InputExample, DataProcessor\n",
    "\n",
    "import logging\n",
    "\n",
    "logger=logging.getLogger(__name__)\n",
    "\n",
    "MODEL_CLASSES={\n",
    "    \"bert\":(BertConfig,BertTokenizer),\n",
    "    \"bertweet\":(BertConfig,BertweetTokenizer)\n",
    "}\n",
    "\n",
    "my_label_list=[0, 1]\n",
    "MAX_SEQ_LENGTH=200\n",
    "\n",
    "class BertForClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = 2\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, self.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "        )\n",
    "\n",
    "        sequence_output, pooled_output=outputs[:2]\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        \n",
    "        outputs = (logits, pooled_output, sequence_output,)\n",
    "\n",
    "        if labels is not None:\n",
    "            \n",
    "            if self.num_labels == 1:\n",
    "                loss_fct = MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        \n",
    "        return outputs  # loss, logits, pooled_output, sequence_output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05d3f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'text_comments'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac6938ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args_eval={\"model_name_or_path\": \"./trained_models/classification_models_\" + model_path,\n",
    "    \"config_name\": \"./trained_models/classification_models_\" + model_path,\n",
    "    \"tokenizer_name\": \"./trained_models/classification_models_\" + model_path,\n",
    "      }\n",
    "\n",
    "config_class, tokenizer_class = MODEL_CLASSES[\"bert\"]\n",
    "model_class=BertForClassification\n",
    "\n",
    "\n",
    "config = config_class.from_pretrained(\n",
    "    args_eval[\"config_name\"],\n",
    "    finetuning_task=\"\", \n",
    "    cache_dir=None,\n",
    ")\n",
    "tokenizer1 = tokenizer_class.from_pretrained(\n",
    "    args_eval[\"tokenizer_name\"],\n",
    "    do_lower_case=True,\n",
    "    cache_dir=None,\n",
    ")\n",
    "model1 = model_class.from_pretrained(\n",
    "    args_eval[\"model_name_or_path\"],\n",
    "    from_tf=bool(\".ckpt\" in args_eval[\"model_name_or_path\"]),\n",
    "    config=config,\n",
    "    cache_dir=None,\n",
    ")\n",
    "\n",
    "\n",
    "model1.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0778721d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\R_BERT\\lib\\site-packages\\transformers\\data\\processors\\glue.py:67: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "data1_features = convert_examples_to_features(data1_InputExamples, tokenizer1, label_list=my_label_list, output_mode=\"classification\",  max_length=MAX_SEQ_LENGTH )\n",
    "\n",
    "\n",
    "val_input_ids = torch.tensor([f.input_ids for f in data1_features], dtype=torch.long)\n",
    "val_attention_mask = torch.tensor([f.attention_mask for f in data1_features], dtype=torch.long)\n",
    "val_token_type_ids = torch.tensor([f.token_type_ids for f in data1_features], dtype=torch.long)\n",
    "val_the_labels = torch.tensor([f.label for f in data1_features], dtype=torch.long)\n",
    "\n",
    "\n",
    "eval_dataset1 = TensorDataset(val_input_ids, val_attention_mask, val_token_type_ids, val_the_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1f06b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, tokenizer, eval_dataset):\n",
    "\n",
    "\n",
    "    logger.info(\"***** Running evaluation  *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "    logger.info(\"  Batch size = %d\", 16)\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "\n",
    "    eval_sampler =RandomSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=16)\n",
    "\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(\"cuda\") for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[3]}\n",
    "            outputs = model(**inputs)\n",
    "            tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "            eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    \n",
    "#     accuracy,f1 = acc_and_f1(preds, out_label_ids)\n",
    "\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8216b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds1 = evaluate(model1, tokenizer1, eval_dataset1)\n",
    "\n",
    "print(preds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d83586c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'comments_only'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a53a5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args_eval={\"model_name_or_path\": \"./trained_models/classification_models_\" + model_path,\n",
    "    \"config_name\": \"./trained_models/classification_models_\" + model_path,\n",
    "    \"tokenizer_name\": \"./trained_models/classification_models_\" + model_path,\n",
    "      }\n",
    "\n",
    "config_class, tokenizer_class = MODEL_CLASSES[\"bert\"]\n",
    "model_class=BertForClassification\n",
    "\n",
    "\n",
    "config = config_class.from_pretrained(\n",
    "    args_eval[\"config_name\"],\n",
    "    finetuning_task=\"\", \n",
    "    cache_dir=None,\n",
    ")\n",
    "tokenizer2 = tokenizer_class.from_pretrained(\n",
    "    args_eval[\"tokenizer_name\"],\n",
    "    do_lower_case=True,\n",
    "    cache_dir=None,\n",
    ")\n",
    "model2 = model_class.from_pretrained(\n",
    "    args_eval[\"model_name_or_path\"],\n",
    "    from_tf=bool(\".ckpt\" in args_eval[\"model_name_or_path\"]),\n",
    "    config=config,\n",
    "    cache_dir=None,\n",
    ")\n",
    "\n",
    "\n",
    "model2.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe8208a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_features = convert_examples_to_features(data2_InputExamples, tokenizer2, label_list=my_label_list, output_mode=\"classification\",  max_length=MAX_SEQ_LENGTH )\n",
    "\n",
    "\n",
    "val_input_ids = torch.tensor([f.input_ids for f in data2_features], dtype=torch.long)\n",
    "val_attention_mask = torch.tensor([f.attention_mask for f in data2_features], dtype=torch.long)\n",
    "val_token_type_ids = torch.tensor([f.token_type_ids for f in data2_features], dtype=torch.long)\n",
    "val_the_labels = torch.tensor([f.label for f in data2_features], dtype=torch.long)\n",
    "\n",
    "\n",
    "eval_dataset2 = TensorDataset(val_input_ids, val_attention_mask, val_token_type_ids, val_the_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91bde1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 15.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds2 = evaluate(model2, tokenizer2, eval_dataset2)\n",
    "\n",
    "print(preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37648e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL POST:\n",
      "\n",
      "So police narrative in #Ferguson is unarmed teen suspected in unarmed robbery was shot to death. We've still got a problem, Chief.\n",
      "\n",
      "COMMENTS\n",
      "Your little narrative is unraveling. That tends to happen when you jump to conclusions.\n",
      "\n",
      "picture of robber shows a weapon\n",
      "\n",
      "so shooting an unarmed black teen in cold blood b/c he could be a robbery suspect is ok?\n",
      "\n",
      "\n",
      "\n",
      "The conclusion that was jumped to was made by officers when they shot MB. (cont)\n",
      "\n",
      "It does not show a weapon. Nor do the police claim there was a weapon. You can read the police report online.\n",
      "\n",
      "just saying cop had reason.to susoect and be alert, if suspect then fought cop or went for gun, that may be reason to shoot\n",
      "\n",
      "You don't know what happened. 'They' shot him? Multiple cops, huh? A few days ago, he was just an innocent kid, remember?\n",
      "\n",
      "oversimplification missing most important piece of narrative--struggle b/t MB &amp; cop, where MB reached for gun...\n",
      "\n",
      "case in court will likely turn on that piece of narrative\n",
      "\n",
      "I explain why on my TL\n",
      "\n",
      "The problem is we know more about the \"strong arm\" robbery of a Swisher Sweet than we do about the confrontation.\n",
      "\n",
      "mostly bc the shoplifting incident is the only thing on camera... again, the explanation is on my TL.  #ShittyButTrue\n",
      "\n",
      "Wondering where the outrage is that a young man felt it acceptable to physically assault &amp; threaten a store owner and steal.\n",
      "\n",
      "Call it triage.\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "ORIGINAL POST:\n",
      "\n",
      "Update: Five hostages escape as a gunman continues siege in Sydney cafe\n",
      "\n",
      "COMMENTS\n",
      "Bastard cops. How dare they help her.\n",
      "\n",
      "Is it escaped or released? Appreciate some clarity on that.\n",
      "\n",
      "its NBC......\n",
      "\n",
      "Bless her!\n",
      "\n",
      "Not all cops are bad.. Their are bad ones just like there is bad humans out there carrying guns legally. stop w/sarcasm.\n",
      "\n",
      "Umm it's Twitter. I will \"sarcasm\" all I want to. Because freedom. Or some shit.\n",
      "\n",
      "Also, it's \"THERE are bad ones\" &amp; \"just like there ARE bad humans\" #spellcheck #grammar\n",
      "\n",
      "thanks God they escape\n",
      "\n",
      "this is sad news.\n",
      "\n",
      "Didn't occur to me that it might not be sarcasm. Was obvious, I thought. The lady has been through hell.\n",
      "\n",
      "â€œ@NBCNews: Update: Five hostages escape as a gunman continues siege in Sydney cafe epidemic\n",
      "\n",
      "i had some very, helpful wonderful policemen ...that helped me when the car broke-down\n",
      "\n",
      "Good to kniw\n",
      "\n",
      "How scary. \"@NBCNews: Update: Five hostages escape as a gunman continues siege in Sydney cafe\n",
      "\n",
      "â€œ@NBCNews: Update: Five hostages escape as a gunman continues siege in Sydney cafe\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "ORIGINAL POST:\n",
      "\n",
      "The selective release of information by #Ferguson PD tells us nothing about the shooting. Instead appears to be a basic smear job.\n",
      "\n",
      "COMMENTS\n",
      "The selective release of information by #Ferguson PD tells us nothing about the shooting. Instead appears to be a basic smear job.\n",
      "\n",
      ".@AlexLittleTN Why people don't trust Cops?\n",
      "They are ALL trained &amp; encouraged by Gov't &amp; prosecutors to\n",
      "\n",
      ".@AlexLittleTN: Did anyone ask where the killer is at this time -if he was still free to roam the streets? He is after all armed &amp; dangerous\n",
      "\n",
      "Contrived, edited, photoshopped, rehearsed. Disgusting. Criminal. #Ferguson\n",
      "\n",
      "basically.\n",
      "\n",
      "Just saw TOM JACKSON reading event's of the lead up to shooting seems put together in a hurry to SMEAR Michael Brown .\n",
      "\n",
      "- and we expected more from the police force that tear gassed a news van?\n",
      "\n",
      ".@AlexLittleTN: I'm not a lawyer so I can boldly say, \"Not 'appears'; this IS a basic smear job, &amp; despite 7 days prep, poorly constructed!\"\n",
      "\n",
      "Yes I believe CHEIF TOM JACKSON did some paper shuffling just as the part of the report of the shooting was about to be read .\n",
      "\n",
      "Because as he ended one part the very next thing he said had no connection with the last statement . Tom left something OUT .\n",
      "\n",
      "The Right Wing Spin Machine is in full Damage Control.\n",
      "\n",
      "the store owner (thru his attorney) NEVER called the police so where did they get the video?\n",
      "\n",
      "Of course this is a smear job...They know this, but did not expect the reaction they are receiving...\n",
      "\n",
      "Where ever he is, he is well protected...they have already circled the wagons around him...\n",
      "\n",
      "I know, As a psychopath it's unlikely, but I still hope he's somewhat worried about the outcome.\n",
      "\n",
      "And NOW the WHOLE WORLD IS WATCHING!!! Can't sweep this under any rug!\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "ORIGINAL POST:\n",
      "\n",
      "Anybody else thinks the #Ferguson police chief is just making this up as he goes along? This is beyond embarrassing. It's shameful!\n",
      "\n",
      "COMMENTS\n",
      "â€œ@rolandsmartin: Anybody else thinks the police chief is just making this up as he goes along? This is beyond embarrassing. It's shameful!â€\n",
      "\n",
      "yep! But the more they talk the more harm they do to their case.\n",
      "\n",
      "No words other than FBI better hold #ferguson pd accountable for any altered&amp;falsified docs-\n",
      "\n",
      "#Ferguson investigation sounds like a Choose your own adventure book! #MikeBrown\n",
      "\n",
      "I am deeply disturbed. A lot of things just don't add up! #Ferguson\n",
      "\n",
      "thinking he needs to stay off mic for sure!\n",
      "\n",
      "It's time for citizens of Ferguson to demand his resignation and appoint a competent person instead.\n",
      "\n",
      "This part of his/their strategy Bring out video at presser that was bout cop name. Now everyone is talking video\n",
      "\n",
      "right...Mike could have paid for it also...\n",
      "\n",
      "yep. Its all about the video now and murderer darren wilson is a nonfactor.\n",
      "\n",
      "truth and justice must be demanded...\n",
      "\n",
      "Aren't there any mature, educated, commen sense ppl working at the #Ferguson PD who'd question what's going on?!\n",
      "\n",
      "any1 wondered y cigars NOT mentioned 2date - I understand no film but Cop said he saw cigars where? hand on ground\n",
      "\n",
      "The good people of #Ferguson have been doing that for several days now.\n",
      "\n",
      "I know they have...and FBI\n",
      "has witness in protective custody.DOJ investigating this whole mess!\n",
      "\n",
      "ROLAND this is an excellent time to have a voter registration movement ,something positive can come from this\n",
      "\n",
      "tragedy ,Some start a nationwide Voter registration drive in Mr BROWNS honor a positive memorial and help end the\n",
      "\n",
      "inequality there\n",
      "\n",
      "It's a Dumb and Dumber police department the \r",
      "chiefs explanations add up to. \"0\".\r",
      "Haven't they interviewed any witnesses?\n",
      "\n",
      "called it this AM\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "ORIGINAL POST:\n",
      "\n",
      "Corporal Nathan Cirillo, shot dead at #Ottawa War Memorial today, was 24. Reservist was member of Argyll and Sutherland Highlanders #cdnpoli\n",
      "\n",
      "COMMENTS\n",
      "Devastating.\n",
      "\n",
      "RIP Corporal Nathan Cirillo, shot dead at #Ottawa War Memorial today, was 24. Reservist was member of Argyll and Sutherland\n",
      "\n",
      "so young!! What a horrible loss for our country :(\n",
      "\n",
      "rip\n",
      "\n",
      "rest peacefully, your duty is done.\n",
      "\n",
      "at the going down of the sun and in the morning we shall remrmbet them RIP Cpl Cirillo\n",
      "\n",
      "May God grant him peace\n",
      "\n",
      "so sad ðŸ™\n",
      "\n",
      "tragic\n",
      "\n",
      "Did you know the connection so desperately sad.\n",
      "\n",
      "tragic and maddening #respect #remembrance #sad\n",
      "\n",
      "so sad\n",
      "\n",
      "RIP Soldier!\n",
      "\n",
      "heartbreaking but Canadians stand together strong\n",
      "\n",
      "Condolences to his family as we struggle to understand how and why this happened.\n",
      "\n",
      "so sad, so pointless!\n",
      "\n",
      "\n",
      "Just tragic.  His family must be devastated.  RIP.  To think that this man was killed at home and not in battle.\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(preds1)):\n",
    "    if preds1[i]==0 and preds2[i]==1:\n",
    "        print('ORIGINAL POST:\\n')\n",
    "        print(sample_data1.iloc[i,0].split('[SEP]')[0])\n",
    "        print('COMMENTS')\n",
    "        for j in range(1,len(sample_data1.iloc[i,0].split('[SEP]'))):\n",
    "            print(sample_data1.iloc[i,0].split('[SEP]')[j])\n",
    "            \n",
    "        print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d4daec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
